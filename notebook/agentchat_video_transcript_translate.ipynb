{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5b4540e-4987-4774-9305-764c3133e953",
   "metadata": {},
   "source": [
    "<a id=\"toc\"></a>\n",
    "# Auto Generated Agent Chat: Translating Video audio using Whisper and GPT-3.5-turbo\n",
    "In this notebook, we demonstrate how to use whisper and GPT-3.5-turbo with `AssistantAgent` and `UserProxyAgent` to recognize and translate\n",
    "the speech sound from a video file and add the timestamp like a subtitle file based on [agentchat_function_call.ipynb](https://github.com/microsoft/autogen/blob/main/notebook/agentchat_function_call.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bdeb0b-c4b6-4dec-97d2-d84f09cffa00",
   "metadata": {},
   "source": [
    "## Set your API Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d1ae87-f007-4286-a56a-dcf68abf9393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import whisper\n",
    "import autogen\n",
    "from moviepy.editor import VideoFileClip\n",
    "import os\n",
    "\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': os.getenv(\"OPENAI_API_KEY\"),\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed549b75-b4ea-4ec5-8c0b-a15e93ffd618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_transcript_from_video(audio_filepath):\n",
    "    try:\n",
    "        # Load model\n",
    "        model = whisper.load_model(\"small\")\n",
    "        with VideoFileClip(audio_filepath) as video:\n",
    "            total_duration = video.duration\n",
    "        # Transcribe audio\n",
    "        result = model.transcribe(audio_filepath)\n",
    "        # Split transcript into sentences and calculate durations\n",
    "        sentences = result['text'].split('. ')\n",
    "        duration_per_sentence = total_duration / len(sentences)\n",
    "        timestamps = [(i * duration_per_sentence, (i + 1) * duration_per_sentence) for i in range(len(sentences))]\n",
    "\n",
    "        # Construct the transcript with timestamps\n",
    "        transcript = [\n",
    "            {\"sentence\": sentence.strip() + \".\", \"timestamp_start\": start, \"timestamp_end\": end}\n",
    "            for sentence, (start, end) in zip(sentences, timestamps)\n",
    "        ]\n",
    "\n",
    "        # Save the transcript to a file\n",
    "        with open(\"transcription.txt\", \"w\") as file:\n",
    "            for item in transcript:\n",
    "                sentence = item[\"sentence\"]\n",
    "                start_time, end_time = item[\"timestamp_start\"], item[\"timestamp_end\"]\n",
    "                file.write(f\"{start_time}s to {end_time}s: {sentence}\\n\")\n",
    "\n",
    "        return transcript\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return \"The specified audio file could not be found.\"\n",
    "    except Exception as e:\n",
    "        return f\"An unexpected error occurred: {str(e)}\"\n",
    "\n",
    "\n",
    "def translate_text(input_text, source_language, target_language):\n",
    "    client = OpenAI(api_key=key)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f\"Translate the following {source_language} text to {target_language}: '{input_text}'\"},\n",
    "        ],\n",
    "        max_tokens=1500\n",
    "    )\n",
    "\n",
    "    # Correctly accessing the response content\n",
    "    translated_text = response.choices[0].message.content if response.choices else None\n",
    "    return translated_text\n",
    "\n",
    "\n",
    "def translate_transcript(source_language, target_language):\n",
    "    with open(\"transcription.txt\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    translated_transcript = []\n",
    "\n",
    "    for line in lines:\n",
    "        # Split each line into timestamp and text parts\n",
    "        parts = line.strip().split(': ')\n",
    "        if len(parts) == 2:\n",
    "            timestamp, text = parts[0], parts[1]\n",
    "            # Translate only the text part\n",
    "            translated_text = translate_text(text, source_language, target_language)\n",
    "            # Reconstruct the line with the translated text and the preserved timestamp\n",
    "            translated_line = f\"{timestamp}: {translated_text}\"\n",
    "            translated_transcript.append(translated_line)\n",
    "        else:\n",
    "            # If the line doesn't contain a timestamp, add it as is\n",
    "            translated_transcript.append(line.strip())\n",
    "\n",
    "    return '\\n'.join(translated_transcript)\n",
    "\n",
    "\n",
    "llm_config = {\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"recognize_transcript_from_video\",\n",
    "            \"description\": \"recognize the speech from video and transfer into a txt file\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"audio_filepath\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"path of the video file\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"audio_filepath\"],\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"translate_transcript\",\n",
    "            \"description\": \"using translate_text function to translate the script\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"source_language\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"source language\",\n",
    "                    },\n",
    "                    \"target_language\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"target language\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"source_language\", \"target_language\"],\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "    \"config_list\": config_list,\n",
    "    \"timeout\": 120,\n",
    "}\n",
    "source_language = \"English\"\n",
    "target_language = \"Chinese\"\n",
    "key = os.getenv(\"OPENAI_API_KEY\")\n",
    "target_video = \"your_file_path\"\n",
    "\n",
    "chatbot = autogen.AssistantAgent(\n",
    "    name=\"chatbot\",\n",
    "    system_message=\"For coding tasks, only use the functions you have been provided with. Reply TERMINATE when the task is done.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    code_execution_config={\"work_dir\": \"coding_2\"},\n",
    ")\n",
    "\n",
    "user_proxy.register_function(\n",
    "    function_map={\n",
    "        \"recognize_transcript_from_video\": recognize_transcript_from_video,\n",
    "        \"translate_transcript\": translate_transcript,\n",
    "    }\n",
    ")\n",
    "user_proxy.initiate_chat(\n",
    "    chatbot,\n",
    "    message=f\"For the video located in {target_video}, recognize the speech and transfer into a script file, \"\n",
    "            f\"then translate from {source_language} text to {target_language} as a subtitle text. \",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
