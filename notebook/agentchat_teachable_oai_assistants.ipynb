{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_teachability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making OpenAI Assistants Teachable\n",
    "\n",
    "Conversational assistants based on LLMs can remember the current chat with the user, and can even demonstrate in-context learning of things that the user teaches the assistant during the chat. But these memories and learnings are lost once the chat is over, or when a single chat grows too long for the LLM to handle effectively. In subsequent chats, the user is forced to repeat any necessary instructions over and over.\n",
    "\n",
    "The optional agent capability called `Teachability` addresses these limitations by persisting user teachings across chat boundaries in long-term memory (a vector database). Memories (called memos) are created and saved to disk throughout a conversation, then loaded from disk later. Instead of copying all the memos into the context window, which would eat up valuable space, individual memos are retrieved into context only as needed. This allows the user to teach many facts, preferences and skills to the teachable agent just once, and have it remember them in later chats.\n",
    "\n",
    "In making decisions about memo storage and retrieval, `Teachability` calls an instance of `TextAnalyzerAgent` to analyze pieces of text in several different ways. This adds extra LLM calls involving a relatively small number of tokens. These calls can add a few seconds to the time a user waits for a response.\n",
    "\n",
    "This notebook demonstrates how `Teachability` can be added to instances of `GPTAssistantAgent`\n",
    "so that they can learn facts, preferences, and skills from users. As explained [here](https://microsoft.github.io/autogen/blog/2023/11/13/OAI-assistants), each instance of `GPTAssistantAgent` wraps an OpenAI Assistant that can be given a set of tools including functions, code interpreter, and retrieval. Assistants with these tools are demonstrated in separate standalone sections below, which can be run independently.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "AutoGen requires `Python>=3.8`. To run this notebook example, please install the [teachable] option.\n",
    "```bash\n",
    "pip install \"pyautogen[teachable]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# %pip install \"pyautogen[teachable]\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4-1106-preview\n"
     ]
    }
   ],
   "source": [
    "import autogen\n",
    "from autogen.agentchat.contrib.capabilities.teachability import Teachability\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    env_or_file=\"OAI_CONFIG_LIST\",\n",
    "    file_location=\".\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\", \"gpt-4-1106-preview\", \"gpt4\", \"gpt-4-32k\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "print(config_list[0][\"model\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It first looks for environment variable \"OAI_CONFIG_LIST\" which needs to be a valid json string. If that variable is not found, it then looks for a json file named \"OAI_CONFIG_LIST\". It filters the configs by models (you can filter by other keys as well). After application of the filter shown above, only the gpt-4 models are considered.\n",
    "\n",
    "The config list may look like the following:\n",
    "```python\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4-1106-preview',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'base_url': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4-32k',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'base_url': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "]\n",
    "```\n",
    "\n",
    "If you open this notebook in colab, you can upload your files by clicking the file icon on the left panel and then choose \"upload file\" icon.\n",
    "\n",
    "You can set the value of config_list in other ways if you prefer, e.g., loading from a YAML file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teachable OpenAI Assistant with Functions\n",
    "This section is based on [agentchat_oai_assistant_function_call.ipynb](https://github.com/microsoft/autogen/blob/teach_cap/notebook/agentchat_oai_assistant_function_call.ipynb), demonstrating how to leverage OSS Insight (Open Source Software Insight) for advanced GitHub data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function schema and implementation\n",
    "\n",
    "This section provides the function schema definition and their implementation details. These functions are tailored to fetch and process data from GitHub, utilizing OSS Insight's capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import requests\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "ossinsight_api_schema = {\n",
    "  \"name\": \"ossinsight_data_api\",\n",
    "  \"parameters\": {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"question\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": (\n",
    "            \"Enter your GitHub data question in the form of a clear and specific question to ensure the returned data is accurate and valuable. \"\n",
    "            \"For optimal results, specify the desired format for the data table in your request.\"\n",
    "        ),\n",
    "      }\n",
    "    },\n",
    "    \"required\": [\n",
    "      \"question\"\n",
    "    ]\n",
    "  },\n",
    "  \"description\": \"This is an API endpoint allowing users (analysts) to input question about GitHub in text format to retrieve the realted and structured data.\"\n",
    "}\n",
    "\n",
    "def get_ossinsight(question):\n",
    "    \"\"\"\n",
    "    Retrieve the top 10 developers with the most followers on GitHub.\n",
    "    \"\"\"\n",
    "    url = \"https://api.ossinsight.io/explorer/answer\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "        \"question\": question,\n",
    "        \"ignoreCache\": True\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        answer = response.json()\n",
    "    else:\n",
    "        return f\"Request to {url} failed with status code: {response.status_code}\"\n",
    "\n",
    "    report_components = []\n",
    "    report_components.append(f\"Question: {answer['question']['title']}\")\n",
    "    if answer['query']['sql']  != \"\":\n",
    "        report_components.append(f\"querySQL: {answer['query']['sql']}\")\n",
    "\n",
    "    if answer.get('result', None) is None or len(answer['result']['rows']) == 0:\n",
    "        result = \"Result: N/A\"\n",
    "    else:\n",
    "        result = \"Result:\\n  \" + \"\\n  \".join([str(row) for row in answer['result']['rows']])\n",
    "    report_components.append(result)\n",
    "\n",
    "    if  answer.get('error', None) is not None:\n",
    "        report_components.append(f\"Error: {answer['error']}\")\n",
    "    return \"\\n\\n\".join(report_components) + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the assistant with function calling as a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT Assistant only supports one OpenAI client. Using the first client in the list.\n",
      "assistant OSS Analyst does not exist, creating a new assistant\n"
     ]
    }
   ],
   "source": [
    "from autogen import config_list_from_json\n",
    "from autogen.agentchat.contrib.gpt_assistant_agent import GPTAssistantAgent\n",
    "from autogen import UserProxyAgent\n",
    "\n",
    "assistant_id = os.environ.get(\"ASSISTANT_ID\", None)\n",
    "config_list = config_list_from_json(\"OAI_CONFIG_LIST\")\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"assistant_id\": assistant_id,\n",
    "     \"tools\": [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": ossinsight_api_schema,\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "oss_analyst = GPTAssistantAgent(\n",
    "    name=\"OSS Analyst\",                            \n",
    "    instructions=(\n",
    "        \"Hello, Open Source Project Analyst. You'll conduct comprehensive evaluations of open source projects or organizations on the GitHub platform, \"\n",
    "        \"analyzing project trajectories, contributor engagements, open source trends, and other vital parameters. \"\n",
    "        \"Please carefully read the context of the conversation to identify the current analysis question or problem that needs addressing.\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    "    verbose=True,\n",
    ")\n",
    "oss_analyst.register_function(\n",
    "    function_map={\n",
    "        \"ossinsight_data_api\": get_ossinsight,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Give the assistant a task involving function calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to OSS Analyst):\n",
      "\n",
      "Top 10 developers with the most followers\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION ossinsight_data_api...\u001b[0m\n",
      "\u001b[35m\n",
      "Input arguments: {'question': 'Who are the top 10 developers with the most followers on GitHub?'}\n",
      "Output:\n",
      "Question: Who are the top 10 developers with the most followers on GitHub?\n",
      "\n",
      "querySQL: SELECT `login` AS `user_login`, `followers` AS `followers` FROM `github_users` ORDER BY `followers` DESC LIMIT 10\n",
      "\n",
      "Result:\n",
      "  {'followers': 196404, 'user_login': 'torvalds'}\n",
      "  {'followers': 96850, 'user_login': 'yyx990803'}\n",
      "  {'followers': 85337, 'user_login': 'gaearon'}\n",
      "  {'followers': 77032, 'user_login': 'ruanyf'}\n",
      "  {'followers': 76251, 'user_login': 'gustavoguanabara'}\n",
      "  {'followers': 68210, 'user_login': 'bradtraversy'}\n",
      "  {'followers': 66512, 'user_login': 'JakeWharton'}\n",
      "  {'followers': 60972, 'user_login': 'peng-zhihui'}\n",
      "  {'followers': 60311, 'user_login': 'sindresorhus'}\n",
      "  {'followers': 59046, 'user_login': 'karpathy'}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[33mOSS Analyst\u001b[0m (to user_proxy):\n",
      "\n",
      "The top 10 developers with the most followers on GitHub are:\n",
      "\n",
      "1. Linus Torvalds (`torvalds`) - 196,404 followers\n",
      "2. Evan You (`yyx990803`) - 96,850 followers\n",
      "3. Dan Abramov (`gaearon`) - 85,337 followers\n",
      "4. Ruan YiFeng (`ruanyf`) - 77,032 followers\n",
      "5. Gustavo Guanabara (`gustavoguanabara`) - 76,251 followers\n",
      "6. Brad Traversy (`bradtraversy`) - 68,210 followers\n",
      "7. Jake Wharton (`JakeWharton`) - 66,512 followers\n",
      "8. Peng Zhihui (`peng-zhihui`) - 60,972 followers\n",
      "9. Sindre Sorhus (`sindresorhus`) - 60,311 followers\n",
      "10. Andrej Karpathy (`karpathy`) - 59,046 followers\n",
      "\n",
      "These developers are among the most followed and likely influential figures in the open source community on GitHub.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user_proxy = UserProxyAgent(name=\"user_proxy\",\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"coding\"\n",
    "    },\n",
    "    is_termination_msg=lambda msg: \"TERMINATE\" in msg[\"content\"],\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=0)\n",
    "\n",
    "user_proxy.initiate_chat(oss_analyst, message=\"Top 10 developers with the most followers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the assistant teachable\n",
    "We can make any `ConversableAgent` teachable by adding a `Teachability` object to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\n",
      "CLEARING MEMORY\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "teachability = Teachability(reset_db=True, llm_config={\"config_list\": config_list})\n",
    "teachability.add_to_agent(oss_analyst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the teachable assistant\n",
    "This time let's teach the assistant a more specific way of formatting lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to OSS Analyst):\n",
      "\n",
      "List the top 10 developers with the most followers. When listing things, please put them in a table.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION ossinsight_data_api...\u001b[0m\n",
      "\u001b[35m\n",
      "Input arguments: {'question': \"List the top 10 developers with the most followers on GitHub. Please provide the data in a table format including the developers' usernames and the number of followers they have.\"}\n",
      "Output:\n",
      "Question: List the top 10 developers with the most followers on GitHub. Please provide the data in a table format including the developers' usernames and the number of followers they have.\n",
      "\n",
      "querySQL: SELECT `login` AS `Developer`, `followers` AS `Followers` FROM `github_users` ORDER BY `followers` DESC LIMIT 10\n",
      "\n",
      "Result:\n",
      "  {'Developer': 'torvalds', 'Followers': 196404}\n",
      "  {'Developer': 'yyx990803', 'Followers': 96850}\n",
      "  {'Developer': 'gaearon', 'Followers': 85337}\n",
      "  {'Developer': 'ruanyf', 'Followers': 77032}\n",
      "  {'Developer': 'gustavoguanabara', 'Followers': 76251}\n",
      "  {'Developer': 'bradtraversy', 'Followers': 68210}\n",
      "  {'Developer': 'JakeWharton', 'Followers': 66512}\n",
      "  {'Developer': 'peng-zhihui', 'Followers': 60972}\n",
      "  {'Developer': 'sindresorhus', 'Followers': 60311}\n",
      "  {'Developer': 'karpathy', 'Followers': 59046}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[33mOSS Analyst\u001b[0m (to user_proxy):\n",
      "\n",
      "Here are the top 10 developers on GitHub with the most followers, presented in a table format:\n",
      "\n",
      "| Developer          | Followers |\n",
      "|--------------------|-----------|\n",
      "| torvalds           | 196,404   |\n",
      "| yyx990803          | 96,850    |\n",
      "| gaearon            | 85,337    |\n",
      "| ruanyf             | 77,032    |\n",
      "| gustavoguanabara   | 76,251    |\n",
      "| bradtraversy       | 68,210    |\n",
      "| JakeWharton        | 66,512    |\n",
      "| peng-zhihui        | 60,972    |\n",
      "| sindresorhus       | 60,311    |\n",
      "| karpathy           | 59,046    |\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user_proxy.initiate_chat(oss_analyst, message=\"List the top 10 developers with the most followers. When listing things, please put them in a table.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see whether the assistant can remember to use our preferred formatting in a new chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to OSS Analyst):\n",
      "\n",
      "List the top 10 developers with the most followers.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION ossinsight_data_api...\u001b[0m\n",
      "\u001b[35m\n",
      "Input arguments: {'question': 'List the top 10 developers with the most followers. Please provide the data in a table format.'}\n",
      "Output:\n",
      "Question: List the top 10 developers with the most followers. Please provide the data in a table format.\n",
      "\n",
      "querySQL: SELECT login AS user_login, followers FROM github_users ORDER BY followers DESC LIMIT 10\n",
      "\n",
      "Result:\n",
      "  {'followers': 196404, 'user_login': 'torvalds'}\n",
      "  {'followers': 96850, 'user_login': 'yyx990803'}\n",
      "  {'followers': 85337, 'user_login': 'gaearon'}\n",
      "  {'followers': 77032, 'user_login': 'ruanyf'}\n",
      "  {'followers': 76251, 'user_login': 'gustavoguanabara'}\n",
      "  {'followers': 68210, 'user_login': 'bradtraversy'}\n",
      "  {'followers': 66512, 'user_login': 'JakeWharton'}\n",
      "  {'followers': 60972, 'user_login': 'peng-zhihui'}\n",
      "  {'followers': 60311, 'user_login': 'sindresorhus'}\n",
      "  {'followers': 59046, 'user_login': 'karpathy'}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[33mOSS Analyst\u001b[0m (to user_proxy):\n",
      "\n",
      "Here are the top 10 developers on GitHub with the most followers, presented in table format:\n",
      "\n",
      "| Rank | User Login         | Followers |\n",
      "|------|--------------------|-----------|\n",
      "| 1    | torvalds           | 196,404   |\n",
      "| 2    | yyx990803          | 96,850    |\n",
      "| 3    | gaearon            | 85,337    |\n",
      "| 4    | ruanyf             | 77,032    |\n",
      "| 5    | gustavoguanabara   | 76,251    |\n",
      "| 6    | bradtraversy       | 68,210    |\n",
      "| 7    | JakeWharton        | 66,512    |\n",
      "| 8    | peng-zhihui        | 60,972    |\n",
      "| 9    | sindresorhus       | 60,311    |\n",
      "| 10   | karpathy           | 59,046    |\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user_proxy.initiate_chat(oss_analyst, message=\"List the top 10 developers with the most followers.\", clear_history=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the teachable assistant\n",
    "All OpenAI Assistants can be created, viewed and deleted manually through OpenAI's [website](https://platform.openai.com/assistants). They can also be deleted through the `GPTAssistantAgent` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permanently deleting assistant...\n"
     ]
    }
   ],
   "source": [
    "oss_analyst.delete_assistant()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flaml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
