{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Telemetry Logging with AutoGen \n",
    "\n",
    "AutoGen offers some utilities to log telemetry data, useful for debugging and performance analysis. This notebook demonstrates how to use these utilities. \n",
    "\n",
    "In general, users can initiate logging by calling `autogen.telemetry.start_logging` and stop logging by calling `autogen.telemetry.stop_logging`, and get logged data by calling `autogen.telemetry.get_log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Telemetry session ID: None\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "What is the height of the Eiffel Tower? Only respond with the answer and terminate\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "The height of the Eiffel Tower is 330 meters (1,083 feet).\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import autogen\n",
    "from autogen import AssistantAgent, UserProxyAgent\n",
    "\n",
    "# start logging telemetry data\n",
    "telemetry_session_id = autogen.telemetry.start_logging(dbname=\"telemetry.db\")\n",
    "print(\"Telemetry session ID: \" + str(telemetry_session_id))\n",
    "\n",
    "## Create an Agent Workflow and Run it\n",
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"gpt-4-turbo-preview\",\n",
    "            \"api_key\": os.environ[\"OPENAI_API_KEY\"],  # Note, add your own API key here\n",
    "        }\n",
    "    ],\n",
    "    \"temperature\": 0.9,\n",
    "}\n",
    "\n",
    "## start_logging\n",
    "assistant = AssistantAgent(name=\"assistant\", llm_config=llm_config)\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"TERMINATE\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "user_proxy.initiate_chat(\n",
    "    assistant, message=\"What is the height of the Eiffel Tower? Only respond with the answer and terminate\"\n",
    ")\n",
    "autogen.telemetry.stop_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data from the SQL Lite Database \n",
    "\n",
    "We can get data from the database by calling `autogen.telemetry.get_log`. This function returns a pandas dataframe with the logged data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>invocation_id</th>\n",
       "      <th>client_id</th>\n",
       "      <th>wrapper_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>request</th>\n",
       "      <th>response</th>\n",
       "      <th>is_cached</th>\n",
       "      <th>cost</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>total_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4f78a8e1-1849-475d-8b27-16ef5ac19965</td>\n",
       "      <td>139914219757312</td>\n",
       "      <td>139914219756016</td>\n",
       "      <td>2430593b-954a-491a-962e-ffd7eba0101f</td>\n",
       "      <td>{\"messages\": [{\"content\": \"You are a helpful A...</td>\n",
       "      <td>{\\n    \"id\": \"chatcmpl-8nBekDzT58BHYVz8KeVcgtv...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-31 21:07:08.154565</td>\n",
       "      <td>2024-01-31 21:07:08.154768</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ecb59f50-85a9-4009-817f-da2a9b2ccd39</td>\n",
       "      <td>140552952983904</td>\n",
       "      <td>140552953221120</td>\n",
       "      <td>aac4f82e-3363-45e6-a2f1-f350ecad23fd</td>\n",
       "      <td>{\"messages\": [{\"content\": \"You are a helpful A...</td>\n",
       "      <td>{\\n    \"id\": \"chatcmpl-8nBekDzT58BHYVz8KeVcgtv...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-31 21:08:52.132000</td>\n",
       "      <td>2024-01-31 21:08:52.132223</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8ebfbb71-bc19-4aa9-ac44-298ac8f26606</td>\n",
       "      <td>140564553711328</td>\n",
       "      <td>140564613259008</td>\n",
       "      <td>6d0728c1-9b7c-43e8-941c-45e3bae0f552</td>\n",
       "      <td>{\"messages\": [{\"content\": \"You are a helpful A...</td>\n",
       "      <td>{\\n    \"id\": \"chatcmpl-8nBekDzT58BHYVz8KeVcgtv...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-31 21:10:00.956998</td>\n",
       "      <td>2024-01-31 21:10:00.957146</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                         invocation_id        client_id       wrapper_id  \\\n",
       "0   1  4f78a8e1-1849-475d-8b27-16ef5ac19965  139914219757312  139914219756016   \n",
       "1   2  ecb59f50-85a9-4009-817f-da2a9b2ccd39  140552952983904  140552953221120   \n",
       "2   3  8ebfbb71-bc19-4aa9-ac44-298ac8f26606  140564553711328  140564613259008   \n",
       "\n",
       "                             session_id  \\\n",
       "0  2430593b-954a-491a-962e-ffd7eba0101f   \n",
       "1  aac4f82e-3363-45e6-a2f1-f350ecad23fd   \n",
       "2  6d0728c1-9b7c-43e8-941c-45e3bae0f552   \n",
       "\n",
       "                                             request  \\\n",
       "0  {\"messages\": [{\"content\": \"You are a helpful A...   \n",
       "1  {\"messages\": [{\"content\": \"You are a helpful A...   \n",
       "2  {\"messages\": [{\"content\": \"You are a helpful A...   \n",
       "\n",
       "                                            response  is_cached  cost  \\\n",
       "0  {\\n    \"id\": \"chatcmpl-8nBekDzT58BHYVz8KeVcgtv...          1   0.0   \n",
       "1  {\\n    \"id\": \"chatcmpl-8nBekDzT58BHYVz8KeVcgtv...          1   0.0   \n",
       "2  {\\n    \"id\": \"chatcmpl-8nBekDzT58BHYVz8KeVcgtv...          1   0.0   \n",
       "\n",
       "                   start_time                    end_time  total_tokens  \n",
       "0  2024-01-31 21:07:08.154565  2024-01-31 21:07:08.154768           511  \n",
       "1  2024-01-31 21:08:52.132000  2024-01-31 21:08:52.132223           511  \n",
       "2  2024-01-31 21:10:00.956998  2024-01-31 21:10:00.957146           511  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def str_to_dict(s):\n",
    "    return json.loads(s)\n",
    "\n",
    "\n",
    "telemetry_df = autogen.telemetry.get_log(table=\"chat_completions\")\n",
    "telemetry_df[\"total_tokens\"] = telemetry_df.apply(\n",
    "    lambda row: str_to_dict(row[\"response\"])[\"usage\"][\"total_tokens\"], axis=1\n",
    ")\n",
    "\n",
    "\n",
    "telemetry_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Cost \n",
    "\n",
    "One use case of telemetry data is to compute the cost of a session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Cost: 0.0\n",
      "Total Tokens: 511\n"
     ]
    }
   ],
   "source": [
    "# total tokens for all sessions .. sum totoal tokens for all sessions\n",
    "total_tokens = telemetry_df[\"total_tokens\"].sum()\n",
    "# total tokens for specific session telemetry_session_id\n",
    "total_tokens = telemetry_df[telemetry_df[\"session_id\"] == telemetry_session_id][\"total_tokens\"].sum()\n",
    "\n",
    "print(\"Total tokens for all sessions: \" + str(total_tokens))\n",
    "print(\"Total tokens for session \" + str(telemetry_session_id) + \": \" + str(total_tokens))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
