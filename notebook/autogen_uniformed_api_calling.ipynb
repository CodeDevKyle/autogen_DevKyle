{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uniform interface for API Calls to different LLMs\n",
    "\n",
    "Autogen provides an uniform interface for API calls to different LLMs. You can also create different agents with different LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config list setup\n",
    "In the setup below, we first create an `OAI_CONFIG_LIST` for different LLMs. \n",
    "\n",
    "```python\n",
    "[\n",
    "    {   \n",
    "        # using OpenAI API\n",
    "        \"model\": \"gpt-35-turbo-1106\",\n",
    "        \"api_key\": \"YOUR_API_KEY\",\n",
    "    },\n",
    "    {\n",
    "        # using Azure API\n",
    "        \"model\": \"gpt-4-turbo-1106\",\n",
    "        \"api_key\": \"YOUR_API_KEY\",\n",
    "        \"api_type\": \"azure\",\n",
    "        \"base_url\": \"YOUR_BASE_URL\",\n",
    "        \"api_version\": \"YOUR_API_VERSION\"\n",
    "    },\n",
    "    {   \n",
    "        # using Google API\n",
    "        \"model\": \"gemini-1.5-pro-latest\",\n",
    "        \"api_key\": \"YOUR_API_KEY\",\n",
    "        \"api_type\": \"google\",\n",
    "    },\n",
    "    {\n",
    "        # using DeepInfra\n",
    "        \"model\": \"meta-llama/Meta-Llama-3-70B-Instruct\",\n",
    "        \"api_key\": \"YOUR_API_KEY\",\n",
    "    },\n",
    "    {\n",
    "        # using DeepInfra\n",
    "        \"model\": \"mistralai/Mixtral-8x22B-Instruct-v0.1\", \n",
    "        \"api_key\": \"YOUR_API_KEY\",\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniform API to call different LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "from autogen import OpenAIWrapper\n",
    "\n",
    "def model_call_example_function(\n",
    "        model: str,\n",
    "        message: str,\n",
    "        cache_seed: int = 41,\n",
    "):\n",
    "    \"\"\"\n",
    "    A helper function that demonstrates how to call different models using the OpenAIWrapper class.\n",
    "    Note the name `OpenAIWrapper` is not accurate, as now it is a wrapper for multiple models, not just OpenAI. \n",
    "    This might be changed in the future.\n",
    "    \"\"\"\n",
    "    config_list = autogen.config_list_from_json(\n",
    "        \"OAI_CONFIG_LIST\",\n",
    "        filter_dict={\n",
    "            \"model\": [model],\n",
    "        }\n",
    "    )\n",
    "    client = OpenAIWrapper(config_list=config_list)\n",
    "    response = client.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": message}],\n",
    "        cache_seed=cache_seed\n",
    "    )\n",
    "\n",
    "    print(f\"Response from model {model}: {response.choices[0].message.content}\")\n",
    "\n",
    "    client.print_usage_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from model gpt-35-turbo-1106: Why don't skeletons fight each other?\n",
      "\n",
      "They don't have the guts.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "No actual cost incurred (all completions are using cache).\n",
      "\n",
      "Usage summary including cached usage: \n",
      "Total cost: 3e-05\n",
      "* Model 'gpt-35-turbo': cost: 3e-05, prompt_tokens: 12, completion_tokens: 15, total_tokens: 27\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_call_example_function(\n",
    "    model=\"gpt-35-turbo-1106\",\n",
    "    message=\"Tell me a joke.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from model gemini-1.5-pro-latest: Why don't scientists trust atoms? \n",
      "\n",
      "Because they make up everything! \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "No actual cost incurred (all completions are using cache).\n",
      "\n",
      "Usage summary including cached usage: \n",
      "Total cost: 0.00042\n",
      "* Model 'gemini-1.5-pro-latest': cost: 0.00042, prompt_tokens: 6, completion_tokens: 18, total_tokens: 24\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_call_example_function(\n",
    "    model=\"gemini-1.5-pro-latest\",\n",
    "    message=\"Tell me a joke.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from model meta-llama/Meta-Llama-3-70B-Instruct: Why couldn't the bicycle stand up by itself?\n",
      "\n",
      "Because it was two-tired!\n",
      "\n",
      "(Sorry, I know it's a bit of a \"dad\" joke, but I hope it made you smile!)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Usage summary excluding cached usage: \n",
      "Total cost: 4e-05\n",
      "* Model 'meta-llama/Meta-Llama-3-70B-Instruct': cost: 4e-05, prompt_tokens: 15, completion_tokens: 41, total_tokens: 56\n",
      "\n",
      "All completions are non-cached: the total cost with cached completions is the same as actual cost.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_call_example_function(\n",
    "    model=\"meta-llama/Meta-Llama-3-70B-Instruct\",\n",
    "    message=\"Tell me a joke. \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using different LLMs in agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list_gpt_35 = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-35-turbo-1106\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "config_list_gemini = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gemini-1.5-pro-latest\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "config_list_llama3 = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"meta-llama/Meta-Llama-3-70B-Instruct\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "config_list_mistral = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"mistralai/Mixtral-8x22B-Instruct-v0.1\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt35_agent = autogen.AssistantAgent(\n",
    "    name=\"Bob\",\n",
    "    system_message=\"You are in the Affirmative team of a debate. When it is your turn, please give at least one reason why you are for the topic.\",\n",
    "    llm_config={\n",
    "        \"cache_seed\": 41,\n",
    "        \"config_list\": config_list_gpt_35\n",
    "    }\n",
    ")\n",
    "\n",
    "llama_agent = autogen.AssistantAgent(\n",
    "    name=\"Alice\",\n",
    "    system_message=\"You are in the Negative team of a debate. The affirmative team has given their reason, please counter their argument.\",\n",
    "    llm_config={\n",
    "        \"cache_seed\": 41,\n",
    "        \"config_list\": config_list_llama3\n",
    "    }\n",
    ")\n",
    "\n",
    "mistral_agent = autogen.AssistantAgent(\n",
    "    name=\"Charlie\",\n",
    "    system_message=\"You are in the Affirmative team of a debate. When it is your turn, please give at least one reason why you are for the topic, or counter the negative team's argument.\",\n",
    "    llm_config={\n",
    "        \"cache_seed\": 41,\n",
    "        \"config_list\": config_list_mistral\n",
    "    }\n",
    ")\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    code_execution_config=False,\n",
    ")\n",
    "\n",
    "groupchat = autogen.GroupChat(agents=[llama_agent, mistral_agent, gpt35_agent, user_proxy], messages=[], max_round=5, speaker_selection_method=\"round_robin\")\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser\u001b[0m (to chat_manager):\n",
      "\n",
      "Debate Topic: Should vaccination be mandatory?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Alice\n",
      "\u001b[0m\n",
      "\u001b[33mAlice\u001b[0m (to chat_manager):\n",
      "\n",
      "Thank you, honorable judges, worthy opponents, and fellow debaters. As the Negative team, I'm excited to counter the Affirmative team's argument that vaccination should be mandatory.\n",
      "\n",
      "While I understand the intention behind making vaccination mandatory, I strongly believe that individual freedom and autonomy should not be compromised. Mandatory vaccination policies would infringe upon a person's right to make informed decisions about their own health and well-being.\n",
      "\n",
      "Firstly, the Affirmative team may argue that mandatory vaccination is necessary to protect public health. However, it's essential to recognize that vaccines are not 100% effective, and outbreaks can still occur even with high vaccination rates. Moreover, there are alternative measures to achieve herd immunity, such as educating the public about the importance of vaccination and improving access to vaccines, rather than forcing individuals to get vaccinated.\n",
      "\n",
      "Secondly, compulsory vaccination raises concerns about individual autonomy and bodily integrity. Vaccines, like any medical treatment, carry risks and potential side effects. Shouldn't individuals have the right to weigh the benefits and risks of vaccination for themselves or their children, rather than being forced to comply with a one-size-fits-all policy? This is particularly important for individuals with compromised immune systems, allergies, or other health conditions that may make vaccination unsafe for them.\n",
      "\n",
      "Thirdly, mandatory vaccination could lead to unintended consequences, such as creating a black market for vaccines or fostering mistrust in the healthcare system. If individuals feel coerced into getting vaccinated, they may be less likely to engage in open and honest discussions with healthcare professionals about their concerns, leading to a breakdown in the patient-provider relationship.\n",
      "\n",
      "Lastly, it's crucial to acknowledge that vaccination policies should be based on scientific evidence, not fear or coercion. While vaccines are an important tool in preventing the spread of diseases, we must also recognize that they are not a panacea. A more effective approach would be to invest in public health infrastructure, improve sanitation, and promote healthy behaviors, rather than relying solely on mandatory vaccination.\n",
      "\n",
      "In conclusion, while the intention behind mandatory vaccination may be noble, it's essential to prioritize individual freedom, autonomy, and informed decision-making. We should focus on educating the public and promoting access to vaccines, rather than resorting to coercion and compromising basic human rights. Thank you.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Charlie\n",
      "\u001b[0m\n",
      "\u001b[33mCharlie\u001b[0m (to chat_manager):\n",
      "\n",
      " Thank you, [INST]. I appreciate the opportunity to provide a counter-argument to the Negative team's viewpoints on the topic of mandatory vaccination.\n",
      "\n",
      "Firstly, I would like to address the concern of individual freedom and autonomy. It is essential to maintain a balance between individual rights and public health. While it is important to respect individuals' choices, it is equally necessary to protect the health of the community, especially vulnerable populations. Mandatory vaccination policies can be carefully crafted to include medical exemptions for those who can't be vaccinated due to legitimate health reasons.\n",
      "\n",
      "Secondly, the Negative team argued that vaccines are not 100% effective, and herd immunity can be achieved through alternative measures such as education and improved access to vaccines. However, relying solely on these strategies can lead to suboptimal outcomes in preventing the spread of diseases. Combining education and access with mandatory vaccination policies can significantly improve overall herd immunity.\n",
      "\n",
      "Thirdly, the argument regarding individual autonomy and bodily integrity is valid. However, it's a matter of striking the right balance between protecting the individual's rights and safeguarding public health. While vaccines carry risks, they have been extensively tested and found to be safe and effective for the vast majority of individuals. Mandatory vaccination policies can be designed to ensure proper communication of risks and benefits, enabling individuals to make informed decisions.\n",
      "\n",
      "Fourthly, the potential unintended consequences of mandatory vaccination, such as the creation of a black market or fostering mistrust in the healthcare system, are speculative. The key to avoiding such scenarios is ensuring transparency, accountability, and effective communication between healthcare professionals, patients, and the general public.\n",
      "\n",
      "Lastly, mandatory vaccination should not be the only focus of public health policies. It is crucial to acknowledge that various factors, such as infrastructure development and healthy lifestyle support, contribute to public health. By implementing mandatory vaccination policies, we are not ignoring the importance of these other factors; instead, we are addressing the specific need to prevent the spread of vaccine-preventable diseases.\n",
      "\n",
      "In conclusion, mandatory vaccination policies can be established in a manner that respects individual autonomy and freedom while balancing public health needs. It is crucial to consider the risks and benefits of mandatory vaccination, as well as the consequences of not adopting such policies. Thank you.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Bob\n",
      "\u001b[0m\n",
      "\u001b[33mBob\u001b[0m (to chat_manager):\n",
      "\n",
      "As the Affirmative team, I am in favor of mandatory vaccination because it is a proven and effective way to prevent the spread of vaccine-preventable diseases and protect public health. Vaccines have been instrumental in reducing the incidence of diseases such as measles, polio, and smallpox, and mandatory vaccination policies help ensure that a sufficient proportion of the population is vaccinated to achieve herd immunity, effectively protecting those who cannot be vaccinated for medical reasons.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: User\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chat_history = user_proxy.initiate_chat(\n",
    "    recipient=manager,\n",
    "    message=\"Debate Topic: Should vaccination be mandatory?\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autodev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
