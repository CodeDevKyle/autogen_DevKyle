{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Auto Builder\n",
    "AutoGen offers conversable agents powered by LLM, tool, or human, which can be used to perform tasks collectively via automated chat. This framework allows tool use and human participation through multi-agent conversation.\n",
    "Please find documentation about this feature [here](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat).\n",
    "\n",
    "In this notebook, we introduce a new class, `AgentCreator`, to help user build an automatic task solving process powered by multi-agent system. Specifically, our building pipeline include `init()`, `build()`, and `start()`. In `build()`, we prompt a gpt-4 model to create multiple participant agent and initialize a group chat, and specify whether this task need programming to solve. After that, user can call `start()` at a proper time to complete the task. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1004af6a7fbfcd8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Requirement\n",
    "\n",
    "Auto Agent setup need `vllm>=0.2.0` and `fastchat>=0.2.30`, you can use the following command to install the latest version of [vLLM](https://github.com/vllm-project/vllm) and [FastChat](https://github.com/lm-sys/FastChat).\n",
    "```\n",
    "pip install vllm \"fastchat[model_worker]\"\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec78dda8e3826d8a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install vllm \"fastchat[model_worker]\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8e9ae50658be975"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Specify a task with detailed information\n",
    "Describe your task in natural language and specify your target (e.g., find some paper from arxiv)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3081403ca3b9b184"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "task=\"Find a latest paper about gpt-4 on arxiv and find its potential applications in software.\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T14:25:51.075351900Z",
     "start_time": "2023-11-08T14:25:51.069815900Z"
    }
   },
   "id": "97221d43eb23768"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare configuration\n",
    "Prepare a `config_path` for assistant agent to limit the choice of LLM you want to use in this task. This config can be a path of json file or a name of environment variable. A `default_llm_config` is also required for initialize the specific config of LLMs like seed, temperature, etc..."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d0e63ab3604bdb9"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "config_path = '/home/elpis_ubuntu/LLM/autogen/OAI_CONFIG_LIST'\n",
    "default_llm_config = {\n",
    "    'temperature': 0\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T14:25:51.612271500Z",
     "start_time": "2023-11-08T14:25:51.603397800Z"
    }
   },
   "id": "2505f029423b21ab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Complete the task building\n",
    "Then, we can use the `AgentCreator` to automatically complete the above task. First, initialize the AgentCreator with the predefined `task` and `config_path`. Then, call the `build` with the `default_llm_config`. GPT-4 will automatically create multiple agents and initialize a groupchat that use to complete this task. Finally, call the `start()` to start the task completion process with a groupchat. When the task begin, groupchat content between each agent will be shown in the console. This process will become interactive when the groupchat manager think that is necessary. Note that if this process involve some open-sourced LLMs (for example, LLaMA 2), an endpoint server will be automatically set up with a background process. You can call the `clear_all()` to wipe them out after the task completed."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2d6586c68fa425b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing usable port...\n",
      "57505 ports found.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai.openai_object'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 8\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mautobuild\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AgentCreator\n\u001B[1;32m      4\u001B[0m administrator \u001B[38;5;241m=\u001B[39m AgentCreator(\n\u001B[1;32m      5\u001B[0m     task,\n\u001B[1;32m      6\u001B[0m     config_path\u001B[38;5;241m=\u001B[39mconfig_path\n\u001B[1;32m      7\u001B[0m )\n\u001B[0;32m----> 8\u001B[0m \u001B[43madministrator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdefault_llm_config\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m administrator\u001B[38;5;241m.\u001B[39mstart()\n\u001B[1;32m     10\u001B[0m administrator\u001B[38;5;241m.\u001B[39mclear_all()\n",
      "File \u001B[0;32m~/LLM/autogen/autobuild/agent_creator.py:206\u001B[0m, in \u001B[0;36mAgentCreator.build\u001B[0;34m(self, default_llm_config, coding)\u001B[0m\n\u001B[1;32m    204\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m coding \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    205\u001B[0m     api \u001B[38;5;241m=\u001B[39m autogen\u001B[38;5;241m.\u001B[39mOpenAIWrapper(config_list\u001B[38;5;241m=\u001B[39mconfig_list)\n\u001B[0;32m--> 206\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mapi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    207\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrole\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCODING_PROMPT\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtask\u001B[49m\u001B[43m)\u001B[49m\u001B[43m}\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    208\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mconfig_list\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m    209\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mchoices[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mmessage\u001B[38;5;241m.\u001B[39mcontent\n\u001B[1;32m    210\u001B[0m     coding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m resp \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mYES\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    212\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m coding \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n",
      "File \u001B[0;32m~/LLM/autogen/autogen/oai/client.py:230\u001B[0m, in \u001B[0;36mOpenAIWrapper.create\u001B[0;34m(self, **config)\u001B[0m\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m seed \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# Try to get the response from cache\u001B[39;00m\n\u001B[1;32m    229\u001B[0m     key \u001B[38;5;241m=\u001B[39m get_key(params)\n\u001B[0;32m--> 230\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mcache\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    231\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    232\u001B[0m         \u001B[38;5;66;03m# check the filter\u001B[39;00m\n\u001B[1;32m    233\u001B[0m         pass_filter \u001B[38;5;241m=\u001B[39m filter_func \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m filter_func(context\u001B[38;5;241m=\u001B[39mcontext, response\u001B[38;5;241m=\u001B[39mresponse)\n",
      "File \u001B[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/diskcache/core.py:1173\u001B[0m, in \u001B[0;36mCache.get\u001B[0;34m(self, key, default, read, expire_time, tag, retry)\u001B[0m\n\u001B[1;32m   1170\u001B[0m ((rowid, db_expire_time, db_tag, mode, filename, db_value),) \u001B[38;5;241m=\u001B[39m rows\n\u001B[1;32m   1172\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1173\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_disk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdb_value\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mread\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1174\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m:\n\u001B[1;32m   1175\u001B[0m     \u001B[38;5;66;03m# Key was deleted before we could retrieve result.\u001B[39;00m\n\u001B[1;32m   1176\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m default\n",
      "File \u001B[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/diskcache/core.py:284\u001B[0m, in \u001B[0;36mDisk.fetch\u001B[0;34m(self, mode, filename, value, read)\u001B[0m\n\u001B[1;32m    282\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mload(reader)\n\u001B[1;32m    283\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 284\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpickle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mBytesIO\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'openai.openai_object'"
     ]
    }
   ],
   "source": [
    "from autobuild import AgentCreator\n",
    "\n",
    "\n",
    "administrator = AgentCreator(\n",
    "    task,\n",
    "    config_path=config_path\n",
    ")\n",
    "administrator.build(default_llm_config)\n",
    "administrator.start()\n",
    "administrator.clear_all()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T14:25:55.341502500Z",
     "start_time": "2023-11-08T14:25:53.472544900Z"
    }
   },
   "id": "7d52e3d9a1bf91cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4ca05bc74723e163"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
