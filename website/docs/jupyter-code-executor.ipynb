{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Code Executor\n",
    "\n",
    "AutoGen is able to execute code in a stateful Jupyter kernel, this is in contrast to the command line code executor where each code block is executed in a new process. This means that you can define variables in one code block and use them in another. One of the interesting properties of this is that when an error is encountered, only the failing code needs to be re-executed, and not the entire script.\n",
    "\n",
    "To use the `JupyterCodeExecutor` you need a Jupyter server running. This can be local, in Docker or even a remove server. Then, when constructing the `JupyterCodeExecutor` you pass it the server it should connect to.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "In order to use Jupyter based code execution some extra depenedencies are required. These can be installed wiht the extra `jupyter-executor`:\n",
    "\n",
    "```bash\n",
    "pip install -qqq 'pyautogen[jupyter-executor]'\n",
    "```\n",
    "\n",
    "## Jupyter Server\n",
    "\n",
    "### Local\n",
    "\n",
    "To run a local Jupyter server, the `LocalJupyterServer` can be used.\n",
    "\n",
    "````{=mdx}\n",
    ":::warning\n",
    "The `LocalJupyterServer` does not function on Windows due to a bug. In this case, you can use the `DockerJupyterServer` instead or use the `EmbeddedJupyterServer`. Do note that the intention is to remove the `EmbeddedJupyterServer` when the bug is fixed.\n",
    ":::\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exit_code=0 output='Hello, World!\\n' output_files=[]\n"
     ]
    }
   ],
   "source": [
    "from autogen.coding import LocalJupyterServer, JupyterCodeExecutor, CodeBlock\n",
    "\n",
    "with LocalJupyterServer() as server:\n",
    "    executor = JupyterCodeExecutor(server)\n",
    "    print(executor.execute_code_blocks(\n",
    "        code_blocks=[\n",
    "            CodeBlock(language=\"python\", code=\"print('Hello, World!')\"),\n",
    "        ]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker\n",
    "\n",
    "To run a Docker based Jupyter server, the `DockerJupyterServer` can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exit_code=0 output='Hello, World!\\n' output_files=[]\n"
     ]
    }
   ],
   "source": [
    "from autogen.coding import DockerJupyterServer, JupyterCodeExecutor, CodeBlock\n",
    "\n",
    "with DockerJupyterServer() as server:\n",
    "    executor = JupyterCodeExecutor(server)\n",
    "    print(executor.execute_code_blocks(\n",
    "        code_blocks=[\n",
    "            CodeBlock(language=\"python\", code=\"print('Hello, World!')\"),\n",
    "        ]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the `DockerJupyterServer` will build and use a bundled Dockerfile, which can be seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM quay.io/jupyter/docker-stacks-foundation\n",
      "\n",
      "SHELL [\"/bin/bash\", \"-o\", \"pipefail\", \"-c\"]\n",
      "\n",
      "USER ${NB_UID}\n",
      "RUN mamba install --yes jupyter_kernel_gateway ipykernel &&     mamba clean --all -f -y &&     fix-permissions \"${CONDA_DIR}\" &&     fix-permissions \"/home/${NB_USER}\"\n",
      "\n",
      "ENV TOKEN=\"UNSET\"\n",
      "CMD python -m jupyter kernelgateway --KernelGatewayApp.ip=0.0.0.0     --KernelGatewayApp.port=8888     --KernelGatewayApp.auth_token=\"${TOKEN}\"     --JupyterApp.answer_yes=true     --JupyterWebsocketPersonality.list_kernels=true\n",
      "\n",
      "EXPOSE 8888\n",
      "\n",
      "WORKDIR \"${HOME}\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(DockerJupyterServer.DEFAULT_DOCKERFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Docker Image\n",
    "\n",
    "A custom image can be used by passing the `custom_image_name` parameter to the `DockerJupyterServer` constructor. There are some requirements of the image for it to work correctly:\n",
    "\n",
    "- The image must have [Jupyer Kernel Gateway](https://jupyter-kernel-gateway.readthedocs.io/en/latest/) installed and running on port 8888 for the `JupyterCodeExecutor` to be able to connect to it.\n",
    "- Respect the `TOKEN` environment variable, which is used to authenticate the `JupyterCodeExecutor` with the Jupyter server.\n",
    "- Ensure the `jupyter kernelgateway` is started with:\n",
    "    - `--JupyterApp.answer_yes=true` - this ensures that the kernel gateway does not prompt for confirmation when shut down.\n",
    "    - `--JupyterWebsocketPersonality.list_kernels=true` - this ensures that the kernel gateway lists the available kernels.\n",
    "\n",
    "\n",
    "If you wanted to add extra dependencies (for example `matplotlib` and `numpy`) to this image you could customize the Dockerfile like so:\n",
    "\n",
    "```Dockerfile\n",
    "FROM quay.io/jupyter/docker-stacks-foundation\n",
    "\n",
    "SHELL [\"/bin/bash\", \"-o\", \"pipefail\", \"-c\"]\n",
    "\n",
    "USER ${NB_UID}\n",
    "RUN mamba install --yes jupyter_kernel_gateway ipykernel matplotlib numpy &&\n",
    "    mamba clean --all -f -y &&\n",
    "    fix-permissions \"${CONDA_DIR}\" &&\n",
    "    fix-permissions \"/home/${NB_USER}\"\n",
    "\n",
    "ENV TOKEN=\"UNSET\"\n",
    "CMD python -m jupyter kernelgateway \\\n",
    "    --KernelGatewayApp.ip=0.0.0.0 \\\n",
    "    --KernelGatewayApp.port=8888 \\\n",
    "    --KernelGatewayApp.auth_token=\"${TOKEN}\" \\\n",
    "    --JupyterApp.answer_yes=true \\\n",
    "    --JupyterWebsocketPersonality.list_kernels=true\n",
    "\n",
    "EXPOSE 8888\n",
    "\n",
    "WORKDIR \"${HOME}\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remote\n",
    "\n",
    "The `JupyterCodeExecutor` can also connect to a remote Jupyter server. This is done by passing connection information rather than an actual server object into the `JupyterCodeExecutor` constructor.\n",
    "\n",
    "```python\n",
    "from autogen.coding import JupyterCodeExecutor, JupyterConnectionInfo\n",
    "\n",
    "executor = JupyterCodeExecutor(\n",
    "    jupyter_server=JupyterConnectionInfo(host='example.com', use_https=True, port=7893, token='mytoken')\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image outputs\n",
    "\n",
    "When Jupyter outputs an image, this is saved as a file into the `output_dir` of the `JupyterCodeExecutor`, as specified by the constructor. By default this is the current working directory.\n",
    "\n",
    "## Assigning to an agent\n",
    "\n",
    "A single server can support multiple agents, as each executor will create its own kernel. To assign an executor to an agent it can be done like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "from autogen.coding import DockerJupyterServer, JupyterCodeExecutor\n",
    "\n",
    "server = DockerJupyterServer()\n",
    "\n",
    "code_executor_agent = ConversableAgent(\n",
    "    name=\"code_executor_agent\",\n",
    "    llm_config=False,\n",
    "    code_execution_config={\n",
    "        \"executor\": JupyterCodeExecutor(server, output_dir=\"coding\"),\n",
    "    },\n",
    "    human_input_mode=\"ALWAYS\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using code execution it is critical that you update the system prompt of agents you expect to write code to be able to make use of the executor. For example, for the `JupyterCodeExecutor` you might setup a code writing agent like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# The code writer agent's system message is to instruct the LLM on how to\n",
    "# use the Jupyter code executor with IPython kernel.\n",
    "code_writer_system_message = \"\"\"\n",
    "You have been given coding capability to solve tasks using Python code in a stateful IPython kernel.\n",
    "You are responsible for writing the code, and the user is responsible for executing the code.\n",
    "\n",
    "When you write Python code, put the code in a markdown code block with the language set to Python.\n",
    "For example:\n",
    "```python\n",
    "x = 3\n",
    "```\n",
    "You can use the variable `x` in subsequent code blocks.\n",
    "```python\n",
    "print(x)\n",
    "```\n",
    "\n",
    "Write code incrementally and leverage the statefulness of the kernel to avoid repeating code.\n",
    "Import libraries in a separate code block.\n",
    "Define a function or a class in a separate code block.\n",
    "Run code that produces output in a separate code block.\n",
    "Run code that involves expensive operations like download, upload, and call external APIs in a separate code block.\n",
    "\n",
    "When your code produces an output, the output will be returned to you.\n",
    "Because you have limited conversation memory, if your code creates an image,\n",
    "the output will be a path to the image instead of the image itself.\"\"\"\n",
    "\n",
    "code_writer_agent = ConversableAgent(\n",
    "    \"code_writer\",\n",
    "    system_message=code_writer_system_message,\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n",
    "    code_execution_config=False,  # Turn off code execution for this agent.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use these two agents to solve a problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_result = code_executor_agent.initiate_chat(\n",
    "    code_writer_agent,\n",
    "    message=\"Write Python code to calculate the 14th Fibonacci number.\",\n",
    ")\n",
    "print(chat_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
