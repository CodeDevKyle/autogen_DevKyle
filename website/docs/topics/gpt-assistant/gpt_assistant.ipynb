{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPTAssistantAgent\n",
    "\n",
    "The GPTAssistantAgent lets you to leverage the power of OpenAI's Assistant API within the AutoGen framework. This enables you to incorporate various functionalities into your agents, including:\n",
    "\n",
    "\n",
    "Multi-Tool Mastery:  Agents can leverage a combination of OpenAI's built-in tools, like [Code Interpreter](https://platform.openai.com/docs/assistants/tools/code-interpreter) and [File Search](https://platform.openai.com/docs/assistants/tools/file-search), alongside custom tools you create or integrate via [Function Calling](https://platform.openai.com/docs/assistants/tools/function-calling).\n",
    "\n",
    "Streamlined Conversation Management:  Benefit from persistent threads that automatically store message history and adjust based on the model's context length. This simplifies development by allowing you to focus on adding new messages rather than managing conversation flow.\n",
    "\n",
    "File Access and Integration:  Enable agents to access and utilize files in various formats. Files can be incorporated during agent creation or throughout conversations via threads. Additionally, agents can generate files (e.g., images, spreadsheets) and cite referenced files within their responses.\n",
    "\n",
    "## How to create a OpenAI Assistant in Autogen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from autogen import config_list_from_json\n",
    "from autogen.agentchat.contrib.gpt_assistant_agent import GPTAssistantAgent\n",
    "\n",
    "assistant_id = os.environ.get(\"ASSISTANT_ID\", None)\n",
    "config_list = config_list_from_json(\"OAI_CONFIG_LIST\")\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "}\n",
    "assistant_config = {\n",
    "    # define the openai assistant behavior as you need\n",
    "}\n",
    "oai_agent = GPTAssistantAgent(\n",
    "    name=\"oai_agent\",\n",
    "    instructions=\"I'm an openai assistant running in autogen\",\n",
    "    llm_config=llm_config,\n",
    "    assistant_config=assistant_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to OpenAI Assistant Built-in Tools and Function Calling\n",
    "\n",
    "### Code Interpreter\n",
    "\n",
    "The [Code Interpreter](https://platform.openai.com/docs/assistants/tools/code-interpreter) empowers your agents to write and execute Python code in a secure environment provide by OpenAI. This unlocks several capabilities, including but not limited to:\n",
    "\n",
    "- Process data: Handle various data formats and manipulate data on the fly.\n",
    "- Generate outputs: Create new data files or even visualizations like graphs.\n",
    "- ...\n",
    "\n",
    "Using the Code Interpreter with the following configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_config = {\n",
    "    \"tools\": [\n",
    "        {\"type\": \"code_interpreter\"},\n",
    "    ],\n",
    "    \"tool_resources\": {\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [\"$file.id\"]  # optional. Files that are passed at the Assistant level are accessible by all Runs with this Assistant.\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the `file.id`, you can employ two methods:\n",
    "\n",
    "1. OpenAI Playground: Leverage the OpenAI Playground, an interactive platform accessible at https://platform.openai.com/playground, to upload your files and obtain the corresponding file IDs.\n",
    "\n",
    "2. Code-Based Uploading: Alternatively, you can upload files and retrieve their file IDs programmatically using the following code snippet:\n",
    "\n",
    "    ```python\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI(\n",
    "        # Defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    )\n",
    "    # Upload a file with an \"assistants\" purpose\n",
    "    file = client.files.create(\n",
    "      file=open(\"mydata.csv\", \"rb\"),\n",
    "      purpose='assistants'\n",
    "    )\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Search\n",
    "\n",
    "The [File Search](https://platform.openai.com/docs/assistants/tools/file-search) tool empowers your agents to tap into knowledge beyond its pre-trained model. This allows you to incorporate your own documents and data, such as product information or code files, into your agent's capabilities.\n",
    "\n",
    "Using the File Search with the following configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_config = {\n",
    "    \"tools\": [\n",
    "        {\"type\": \"file_search\"},\n",
    "    ],\n",
    "    \"tool_resources\": {\n",
    "        \"file_search\": {\n",
    "            \"vector_store_ids\": [\"$vector_store.id\"]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to obtain the vector_store.id using two methods:\n",
    "\n",
    "1. OpenAI Playground: Leverage the OpenAI Playground, an interactive platform accessible at https://platform.openai.com/playground, to create a vector store, upload your files, and add it into your vector store. Once complete, you'll be able to retrieve the associated `vector_store.id`.\n",
    "\n",
    "2. Code-Based Uploading:Alternatively, you can upload files and retrieve their file IDs programmatically using the following code snippet:\n",
    "\n",
    "    ```python\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI(\n",
    "        # Defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    )\n",
    "\n",
    "    # Step 1: Create a Vector Store\n",
    "    vector_store = client.beta.vector_stores.create(name=\"Financial Statements\")\n",
    "    print(\"Vector Store created:\", vector_store.id)  # This is your vector_store.id\n",
    "\n",
    "    # Step 2: Prepare Files for Upload\n",
    "    file_paths = [\"edgar/goog-10k.pdf\", \"edgar/brka-10k.txt\"]\n",
    "    file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "\n",
    "    # Step 3: Upload Files and Add to Vector Store (with status polling)\n",
    "    file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "        vector_store_id=vector_store.id, files=file_streams\n",
    "    )\n",
    "\n",
    "    # Step 4: Verify Completion (Optional)\n",
    "    print(\"File batch status:\", file_batch.status)\n",
    "    print(\"Uploaded file count:\", file_batch.file_counts.processed)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function calling\n",
    "\n",
    "Function Calling empowers you to extend the capabilities of your agents with your pre-defined functionalities, which allows you to describe custom functions to the Assistant, enabling intelligent function selection and argument generation.\n",
    "\n",
    "Using the Function calling with the following configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn more from https://platform.openai.com/docs/guides/function-calling/function-calling\n",
    "api_schema = \"define your function schema here\"\n",
    "assistant_config = {\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": api_schema,\n",
    "        }\n",
    "    ],\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
