{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_groupchat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Generated Agent Chat: Group Chat 自動產生的代理聊天：群聊\n",
    "\n",
    "AutoGen 提供由 LLM、工具或人員支援的可對話代理，可用於透過自動聊天集體執行任務。 該框架允許透過多代理對話使用工具和人類參與。\n",
    "請在[此處](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat)尋找有關此功能的文件。\n",
    "\n",
    "本筆記本根據https://github.com/microsoft/FLAML/blob/4ea686af5c3e8ff24d9076a7a626c8b28ab5b1d7/notebook/autogen_multiagent_roleplay_chat.ipynb修改\n",
    "\n",
    "## Requirements\n",
    "\n",
    "AutoGen requires `Python>=3.8`. To run this notebook example, please install:\n",
    "```bash\n",
    "pip install pyautogen\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# %pip install \"pyautogen>=0.2.3\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint 設定您的 API 端點\n",
    "\n",
    "[`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) 函數從環境變數或 json 檔案載入設定清單。\n",
    "\n",
    "將調用的大模型改成 gpt-3.5，以節省費用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "\"\"\" config_list_gpt = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\", \"gpt-4-0314\", \"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\", \"gpt-4-32k-v0314\"],\n",
    "    },\n",
    ") \"\"\"\n",
    "config_list_gpt = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": {\n",
    "            \"gpt-3.5-turbo\",\n",
    "            \"gpt-3.5-turbo-16k\",\n",
    "            \"gpt-3.5-turbo-0301\",\n",
    "            \"chatgpt-35-turbo-0301\",\n",
    "            \"gpt-35-turbo-v0301\",\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "它首先查找環境變數“OAI_CONFIG_LIST”，該變數需要是有效的 json 字串。 如果未找到該變量，它將尋找名為“OAI_CONFIG_LIST”的 json 檔案。 它按型號過濾配置（您也可以按其他鍵過濾）。 根據過濾條件，僅 gpt-3.5 型號保留在清單中。\n",
    "\n",
    "配置列表如下所示：\n",
    "```python\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"api_key\": \"sk-xxx\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"gpt-3.5-turbo-1106\",\n",
    "        \"api_key\": \"sk-xxx\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"gpt-3.5-turbo-0613\",\n",
    "        \"api_key\": \"sk-xxx\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"gpt-3.5-turbo-16k\",\n",
    "        \"api_key\": \"sk-xxx\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"gpt-3.5-turbo-16k-0613\",\n",
    "        \"api_key\": \"sk-xxx\"\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "您可以按照您喜歡的任何方式設定 config_list 的值。 請參閱此[筆記本](https://github.com/microsoft/autogen/blob/main/notebook/oai_openai_utils.ipynb)以取得不同方法的完整程式碼範例。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Agents 建立代理(智能體)\n",
    "config_list_gpt 裡面過濾後還有 5 的 gpt-3.5。不確定下面指令執行後，在 autogen.AssistantAgent 設定 llm_config=llm_config 是會去掉用哪一個 gpt-3.5 ?\n",
    "\n",
    "llm_config = {\"config_list\": config_list_gpt, \"cache_seed\": 42}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\"config_list\": config_list_gpt, \"cache_seed\": 42}\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User_proxy\",\n",
    "    system_message=\"A human admin.\",\n",
    "    code_execution_config={\"last_n_messages\": 2, \"work_dir\": \"groupchat\"},\n",
    "    human_input_mode=\"TERMINATE\",\n",
    ")\n",
    "coder = autogen.AssistantAgent(\n",
    "    name=\"Coder\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "pm = autogen.AssistantAgent(\n",
    "    name=\"Product_manager\",\n",
    "    system_message=\"Creative in software product ideas.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, coder, pm], messages=[], max_round=12)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Chat 開始對話\n",
    "\n",
    "並要求以繁體中文回應(And reponse in traditional chinese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=\"Find a latest paper about gpt-4 on arxiv and find its potential applications in software. And reponse in traditional chinese.\",\n",
    ")\n",
    "# type exit to terminate the chat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flaml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
